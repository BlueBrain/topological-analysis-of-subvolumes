#+title: Connsense Topology Pipeline for SSCx

We an provide a litte header for the pipeline
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
description: >-
  Configure a connsense subTarget Analysis Pipeline to analyze your circuit.
version: 0.1.0
date: <2023-02-13 Mon>
#+end_src

* paths
We need to set paths to the artefacts that the pipeline will use. We set paths for the circuit to analyze, and the root space for the pipeline's HDF5 stores, and the HDF5 group for each of the pipeline steps.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
paths:
  description: >-
    The ~connsense~ pipeline needs paths to the input data to load from, and output paths to store data.
    Paths to the circuit must be provided along with paths to the HDF5 archive that will store the pipeline's
    results.
  format: relative
  circuit:
    root: "/gpfs/bbp.cscs.ch/project/proj83/circuits"
    files:
      Bio_M: "Bio_M/20200805/CircuitConfig_TC_WM"
  pipeline:
    root: "/gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2"
    input:
      store: "connsense.h5"
    output:
      store: "connsense.h5"
    steps:
      define-subtargets: "subtargets"
      extract-node-populations: "nodes/populations"
      extract-edge-populations: "edges/populations"
      analyze-connectivity: "analyses/connectivity"
#+end_src

* parameters
We provide the parameters for each step.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
parameters:
  description: >-
    Provide parameters that apply to each step.
#+end_src
The pipeline will ~define~ the ~subtargets~, ~extract~ circuit artefacts for the ~subtargets~, and ~analyze~ the results. Each of these ~steps~ need to be defined.

** define-subtargets
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
  define-subtargets:
    description: >-
      Configure the subtargets to analyze, entrying each definition as a key, value.
    definitions:
#+end_src
We define ~flatmap-columns~ which are prism like columns orientated along cortical layers, from white-matter to pia. The data is loaded from an ~NRRD~ that maps each circuit voxel to an ~id~ that corresponds to ~flatmap-column-subtarget~. We also need ~info~, a ~dataframe~ that provides information about these ~subtargets~ indexing them by the ~id~ from the ~NRRD~.
*** flatmap-columns
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
      flatmap-columns:
        description: >-
          Hexaongal prism like columns oriented along cortical layers,
          from white-matter to pia.  The data is loaded from an NRRD file that maps each
          circuit voxel to a subtarget ids corresponding to a flatmap column.The subtarget
          ids should be mapped to the subtargets they refer to in a dataframe provided as
          the input `info`.
        input:
          circuit:
          - "Bio_M"
        kwargs:
          path: "/gpfs/bbp.cscs.ch/project/proj83/home/reimann/subvolumes/column_identities.nrrd"
          info: "/gpfs/bbp.cscs.ch/project/proj83/home/reimann/subvolumes/voxel-based-hex-grid-info-with-conicality.h5"
        loader:
          source: connsense.define_subtargets.flatmap
          method: load_nrrd
#+end_src
The ~input~ is set to a label that should appear among ~config-paths~. The ~loader~ method used is expected to take a ~bluepy.Circuit~ instance as an argument, which will be passed by ~connsense~.

** create-index
Within ~connsense~ we use an ~internal~ index for ~subtarget, circuit, connectome~. While we can infer this information from [[paths]] and [[define-subtargets]], we have not yet (<2023-02-13 Mon>) implemented this feature.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
  create-index:
    description:
      Create tap-store indices by listing datasets for each index variable.
    variables:
      circuit:
        - "Bio_M"
      connectome:
        - "local"
      subtarget:
        dataset: ["define-subtargets", "flatmap-columns/name"]
#+end_src
** extract-node-populations
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
  extract-node-populations:
    description: >-
      Specify the populations to extract from a circuit.
    populations:
#+end_src

*** default
The population of /non-barrel/ SSCx biophysical nodes will be the node-population that we analyze,
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
      default:
        description: >-
          The default population will be that of neurons in the SSCx.
          To extract the neurons we will use a `connsense` method that uses ~bluepy~.
        input:
          subtarget:
            dataset:  ["define-subtargets", "flatmap-columns"]
          circuit:
            - "Bio_M"
        kwargs:
          properties:
            - region
            - layer
            - x
            - y
            - z
            - depth
            - synapse_class
            - mtype
            - etype
            - morphology
        extractor:
          source: connsense.extract_nodes.bluepy
          method: extract_node_properties
        output: "pandas.DataFrame"
#+end_src
** extract-edge-populations
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
  extract-edge-populations:
    description: >-
      Specify the edge populations to extract from a circuit.
    populations:
#+end_src
We will analyze topology of the ~local~ connectome that consists of the connections among cells based on their axo-dendritic appositions. To study the local connectivity of a ~subtarget~, we will need it's adjacency matrix that we can extract to the ~TAPStore~.

*** local
The population of local connections resulting from axo-dendritic appositions.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
      local:
        input:
          subtarget:
            dataset:  ["define-subtargets", "flatmap-columns"]
          circuit:
            - "Bio_M"
          connectome:
            - "local"
        extractor:
          source: connsense.extract_connectivity.bluepy
          method: extract_adj
        output: "sparse.spmatrix"
#+end_src
** analyze-connectivity
We will analyze several phenomena related to network topology, each entered in ~analyses~,
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
  analyze-connectivity:
    description: >-
      Configure each analyses' parameters, as a mapping under section `analyses`.
    analyses:
#+end_src
*** simplex-counts
We count the number of /simplices/ that is complete subgraphs of a given dimension /i.e/ the number of edges in the simplex. So a node is a simplex of dimension 0, an edge of dimension 1 while a dimension 2 will be a triangle. We will compute a series of simplex counts by dimension for each subtarget, 5 of it's Erdos-Renyi controls, subgraphs in each layer and their ER controls.
**** description
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
      simplex-counts:
        description: >-
          Number of simplices by dimension.
#+end_src
**** input
We will compute ~simplex-counts~ for each of the ~flatmap-columns~, using ~adjacency~ matrices that we extract as dataset ~("extract-edge-populations", "local")~. We will also use ~node_properties~ that we extract as ~node-population~ ~default~.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
        input:
          node_properties:
            dataset: ["extract-node-populations", "default"]
          adjacency:
            dataset: ["extract-edge-populations", "local"]
#+end_src
**** controls
We will use random controls for each ~subtarget~, entering them by name and value. We start with Erdos-Renyi controls, 5 of them specified by seed.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
        controls:
          erdos-renyi:
            description: >-
              Erdos-Renyi shuffle of edges.
            seeds: [0, 1, 2, 3, 4]
            algorithm:
              source: "/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py"
              method: "ER_shuffle"
#+end_src
**** slicing
We will slice each ~subtarget~ into ~subtgraphs~ consisting of each of the cortical layers. Thus a single ~subtarget~ should give us 6 of these ~slicings~. To compute analysis on a ~slicing~ we will have to enter it inside the ~analysis~ config.

We may store computation of each slice of a single subtarget as a ~datacall~. This will result in each slice of each subtarget to be sequenced as a ~unit-computation~. In ~connsense-parallelization~, we then parallelize based on the sizes of all the slices. The computation is seprated from that of ~full-subtargets~. This does not work well with ~simplex-counts~ as ~datacall~ of a single ~slice~ requires us to first load the adjacency matrices, then control them. With large adjacency matrices the computation of a unit ~slice-subtarget~ will require the same resources as loading the original full and randomizing it. Instead we will have to serially compute the slices' simplex-counts for each subtarget.

We can specify this in the config as ~compute_mode: EXECUTE~, instead of ~DATACALL~ which will create individual ~datacalls~, or ~DATASET~ that should save each ~slice-subtarget~ to a ~TapDataset~.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
        slicing:
          description: >-
            Slice analysis input according to some rules.
          do-full: true #to run the original full matrices as well...
          layer:
            description: >-
              Intralayer subgraphs.
            compute_mode: EXECUTE
            slices:
              layer: [1, 2, 3, 4, 5, 6]
            algorithm:
              source: "/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py"
              method: "subgraph_intralayer"
#+end_src
**** computation
Finally, we need to specify the method to use to compute ~simplex-counts~ for each ~subtarget~, and the data-type of it's output.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
        computation:
          source: "/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py"
          method: "simplex_counts"
        output: "pandas.Series"
#+end_src

*** model-params-dd2
This analysis is used to create parameters for the distance dependent connection-probablity order 2 control model.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
      model-params-dd2:
        description: >-
          Parameters for distance dependent connectivity model of order 2.
          Note that the `coord_names` in key `kwargs:` must agree with the configuration
          of the control model that will use the results of this analysis.
#+end_src
**** input
We will compute ~simplex-counts~ for each of the ~flatmap-columns~, using ~adjacency~ matrices that we extract as dataset ~("extract-edge-populations", "local")~. We will also use ~node_properties~ that we extract as ~node-population~ ~default~.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
        input:
          node_properties:
            dataset: ["extract-node-populations", "default"]
          adjacency:
            dataset: ["extract-edge-populations", "local"]
#+end_src
**** computation
Finally, we need to specify the method to use to compute ~simplex-counts~ for each ~subtarget~, and the data-type of it's output.
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
        computation:
          source: "/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/modelling.py"
          method: "conn_prob_2nd_order_model"
        output: "pandas.DataFrame"
#+end_src
**** kwargs
The method that we will use to compute model parameters needs these parameters,
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
        kwargs:
          bin_size_um: 50
          max_range_um: 1000
          sample_size: null
          coord_names: ["x", "y", "z"]
#+end_src

* Scratch
#+header: :comments both :padline no :tangle ./pipeline.yaml
#+begin_src yaml
#+end_src
