#+PROPERTY: header-args:jupyter-python :session ~/Library/Jupyter/runtime/active-1-ssh.json
#+PROPERTY: header-args:jupyter :session ~/Library/Jupyter/runtime/active-1-ssh.json
#+STARTUP: overview

#+title: (sub) Target Analysis Pipeline


* Feedback
** from last <2022-10-04 Tue>
*** Thu Oct 13 10:36:27 2022
I felt that it is possible to motivate a problem-domain-specific schema can be developed. But we have to find the right balance between parts of the configuration that go into the ~pipeline-config~ file and those that go into the ~methods~ that execute pipeline computations. Above all, the ~pipeline-config~ file should tell a story about what the scientist wants.


* To analyze sub-targets in a circuit.

*connsense-TAP*  offers a solution to a problem,

** PROBLEM

Our circuits are as detailed as the current state of the art experimental data and algorithms allow. Circuit data artefacts are complex and ridden with neuroscience and informatics jargon --- both of which can be a hurdle in analyzing a circuit reconstruction.

1. Physically large circuit --- analyses, unless parallelized, can be slow

2. Book-keeping analyses results can be a head-ache

3. Too much neuroscientific and informatic jargon to load a circuit to analyze


** SOLUTION: TAP

*** ~tap-env~: Circuit Analysis Compute Environemnt
Follow conventions to provide methods on individual ~circuit-subtargets~ that ~TAP~ will parallelize.

*** ~tap-store~: A HDFstore to hold the analysis data
Use an interface to interact with the analyzed data and generate reports

*** ~tap-config~: A Reporducible document in the form of a YAML / JSON config file
Use the config to reproduce analyses on existing or new circuits.


* SUBTARGET

A ~connsense-TAP~ analysis will be that of a ~circuit-subtarget~, that can be represented simply as a collection of ~node-ids~. For example, we may parcellate the brain's physical shape into constituent blocks, and study how a brain circuit phenomenon varies across the /sub-circuits/ composed of cells in these blocks. In ~connsense-TAP~ these blocks will be considered as ~circuit-subtargets~ for an analysis.

The rat-SSCx circuit has 8 subregions, with a total of 4.5 million neurons. The upcoming mouse-IsoCortex will have the entire neocortex with more than 10 million neurons. The whole circuit may be too big for an analysis. We have defined representative ~central-columns~ in each of the SSCX-Rat circuit's regions as ~circuit-subtargets~

Or we may be interested in a brain-circuit parcellation that arises from a biological phenomenon, and define ~subtargets~ accordingly. Parcellation of the SSCx into /conical/ ~flatmap-columns~ oriented along cortical layers is being used to study the composition and connectivity in relation to white-matter innervation that follows a similar columnar pattern.

In ~connsense-TAP~ we can configure analyses of ~flatmap-column~ ~circuit-subtargets~. The diameter of each column at it's base was set to $230.0\mu m$ which is roughly the size of a large L5 TPC.

#+begin_src jupyter-python :tangle develop_topotap.py
from flatmap_utility import subtargets as fmst, tessellate
from bluepy import Circuit
circuit = Circuit("//gpfs/bbp.cscs.ch/project/proj83/circuits/Bio_M/20200805/ch/project"
                  "/proj83/circuits/Bio_M/20200805/CircuitConfig_TC_WM")
flat_xys = fmst.fmap_positions(in_data=circuit)
tritille = tessellate.TriTille(230.0)
fig_fmap_cells = plt.figure(figsize=(8, 8))
ax = fig_fmap_cells.add_subplot(111, aspect=1.)
graphic_fmap_cells = tritille.plot_hextiles(fxys, graphic=(fig, ax),
                                            annotate=False, with_grid=False, pointmarker=".", pointmarkersize=0.05))
fig_fmap_cells

#+end_src

#+RESULTS:
[[file:./.ob-jupyter/1179885101204eb0ecc0024922e22784b9314ed0.png]]




* Interface to TAP: How to work with the analyses data?

We can use a ~class~ defined in ~connsense-TAP~ to interface with the data that has been extracted.

** Setup
*** A notebook template to explore and develop

Let us setup an interactive ~Python~ session where we can run the code developed here.

#+begin_src jupyter
print("Welcome to EMACS Jupyter")
#+end_src

#+RESULTS:
: Welcome to EMACS Jupyter

*** Introduction

#+name: notebook-init
#+begin_src jupyter-python
from importlib import reload
from collections.abc import Mapping
from collections import OrderedDict
from pprint import pprint, pformat
from pathlib import Path

import numpy as np
import pandas as pd

import matplotlib

reload(matplotlib)
from matplotlib import pylab as plt
import seaborn as sbn
GOLDEN = (1. + np.sqrt(5.))/2.

from IPython.display import display

from bluepy import Synapse, Cell, Circuit

print("We will plot golden aspect ratios: ", GOLDEN)
#+end_src

#+RESULTS: notebook-init
: We will plot golden aspect ratios:  1.618033988749895

We have run ~connsense-TAP~ for the SSCx dissemination variant /Bio-M/, extracting data that we will use to study the circuit's topology. Here are some workspaces that we use to /test-develop/ ~connsense-TAP~ for topology.

*** Workspaces

We have a ~connsense-TAP~ pipeline with circuit data extracted for the ~flatmap-columns~.

#+name: notebook-workspaces
#+begin_src jupyter-python
from connsense.pipeline import pipeline
from connsense.develop import parallelization as devprl

from connsense.pipeline.store import store as tap_store
from connsense.develop import topotap as devtap

ROOTSPACE = Path("/")
PROJSPACE = ROOTSPACE / "gpfs/bbp.cscs.ch/project/proj83"
CONNSPACE = PROJSPACE / "home/sood" / "topological-analysis-subvolumes/test/v2"
#+end_src

#+RESULTS: notebook-workspaces

While test-developing it will be good to have direct access to the ~connsense-TAP-store~ we will use. We will use a development version of the interface.

*** ~connsense~ Modules

#+name: notebook-connsense-tap
#+begin_src jupyter-python
tap = devtap.HDFStore(CONNSPACE/"pipeline.yaml")
print("Configured Analyses: ")
pprint(tap.analyses)
#+end_src

#+RESULTS: notebook-connsense-tap
: Configured Analyses:
: {'connectivity': {'model-params-dd2': <connsense.develop.topotap.TapDataset object at 0x7ffdf351a760>,
:                   'simplex-counts': <connsense.develop.topotap.TapDataset object at 0x7ffdf36820a0>}}

*** Notebook template

Finally, here is a template that we can use to start test-developing. We will deposit the code in a sub-directory, of the directory holding this file.

#+begin_src jupyter-python :tangle develop_topotap.py :comments no :noweb yes :padline yes
# %% [markdown]
"""# Test Develop a Circuit Factology
"""

# %% [code]
<<notebook-init>>

<<notebook-workspaces>>

<<notebook-connsense-tap>>

<<notebook-reloads>>


#+end_src

#+RESULTS:
: We will plot golden aspect ratios:  1.618033988749895
: Configured Analyses:
: {'connectivity': {'model-params-dd2': <connsense.develop.topotap.TapDataset object at 0x7fff1db69af0>,
:                   'simplex-counts': <connsense.develop.topotap.TapDataset object at 0x7fff1e0ddfd0>}}


We will use the deprecated ~connsense-TAP-HDFStore~ to load the circuit. We need the circuit for our discussion. ~connsense-TAP~ can be used without accessing the circuit itself.
#+begin_src jupyter-python :tangle develop_topotap.py
otap = tap_store.HDFStore(tap._config)
circuit = otap.get_circuit("Bio_M")
#+end_src

#+RESULTS:
:  2022-11-15 11:41:51,714: Load circuit Bio_M

** Nodes and their Adjacencies

For topological analyses we will need the adjacency-matrix and node-properties for the cells in a ~flatmap-column~. Let us see what these quantities look like.

*** Node properties

#+begin_src jupyter-python :tangle develop_topotap.py
nodes = tap.nodes
nodes.dataset
#+end_src

#+RESULTS:
:RESULTS:
:  2022-11-15 15:42:32,774: Load dataset ('extract-node-populations', 'default'):
: ('The default population will be that of neurons in the SSCx. To extract the '
:  'neurons we will use a `connsense` method that uses ~bluepy~.')
:  2022-11-15 15:42:33,308: Initialize a DataFrameStore matrix store loading / writing data at /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/connsense.h5 / nodes/populations/default
#+begin_example
subtarget_id  circuit_id
1             0             <connsense.analyze_connectivity.matrices.BeLaz...
2             0             <connsense.analyze_connectivity.matrices.BeLaz...
3             0             <connsense.analyze_connectivity.matrices.BeLaz...
4             0             <connsense.analyze_connectivity.matrices.BeLaz...
5             0             <connsense.analyze_connectivity.matrices.BeLaz...
                                                  ...
235           0             <connsense.analyze_connectivity.matrices.BeLaz...
236           0             <connsense.analyze_connectivity.matrices.BeLaz...
237           0             <connsense.analyze_connectivity.matrices.BeLaz...
238           0             <connsense.analyze_connectivity.matrices.BeLaz...
239           0             <connsense.analyze_connectivity.matrices.BeLaz...
Length: 239, dtype: object
#+end_example
:END:

Each entry in the dataset is /lazy/, and can be loaded to get the node properties,

#+begin_src jupyter-python :tangle develop_topotap.py
nodes.dataset.iloc[0].get_value()
#+end_src

#+RESULTS:
:RESULTS:
:  2022-11-15 12:25:37,667: Initialize a DataFrameStore matrix store loading / writing data at /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/connsense.h5 / nodes/populations/default
#+begin_example
             gid region  layer            x            y            z  \
node_id
0        1636113   S1HL      6  1717.806055  1429.243660 -1947.592157
1         996599   S1HL      6  1706.644663  1483.742710 -1753.324454
2        3524820   S1HL      5  1753.483392  1376.686423 -1307.496527
3          14591   S1HL      3  1870.540963  1503.039073  -832.308098
4        4075085   S1HL      5  1762.695366  1617.381668 -1350.106825
...          ...    ...    ...          ...          ...          ...
4565     2482024   S1HL      4  1870.852629  1417.927526 -1074.505226
4566      149550   S1HL      3  1801.080746  1381.376679  -936.636220
4567     1262062   S1HL      6  1726.608297  1578.411602 -1954.463973
4568     2482234   S1HL      4  1815.534162  1368.098461 -1149.196962
4569     2565585   S1HL      4  1849.944804  1458.358325 -1125.779489

        synapse_class     mtype   etype  \
node_id
0                 EXC    L6_IPC  cADpyr
1                 EXC    L6_UPC  cADpyr
2                 EXC    L5_UPC  cADpyr
3                 EXC  L3_TPC:A  cADpyr
4                 EXC  L5_TPC:A  cADpyr
...               ...       ...     ...
4565              EXC    L4_TPC  cADpyr
4566              EXC  L3_TPC:A  cADpyr
4567              EXC    L6_HPC  cADpyr
4568              EXC    L4_TPC  cADpyr
4569              EXC    L4_TPC  cADpyr

                                                morphology        depth
node_id
0        dend-mtC040800E_idF_axon-tkb061213a1_ch0_cc1_h...  1417.501919
1            dend-Fluo12_right_axon-Fluo41_right_-_Clone_0  1020.287498
2        dend-vd110524_idB_axon-rp100426-1_idF_-_Scale_...   560.620309
3        dend-C190898A-P3_axon-mtC221001B_idE_-_Scale_x...   305.047515
4        dend-rp090908_c3_axon-rp111203_C3_idA_-_Scale_...   765.092867
...                                                    ...          ...
4565                dend-rp120608_P_3_idA_axon-C310897A-P4   514.898934
4566     dend-rr110125B_idA_axon-C280199C-P1_-_Scale_x1...   366.843276
4567     dend-og060905b1-4_idC_axon-cr161021_A_idB_-_Sc...  1465.592792
4568     dend-C310897A-P4_axon-rp120531_P_2_idC_-_Scale...   395.760671
4569     dend-rp120914_P_1_idC_axon-sm100429a1-5_INT_id...   569.395353

[4570 rows x 11 columns]
#+end_example
:END:

*** Adjacency

We can have more than one connectome in the circuit, and thus ~connsense-TAP-adjacency~ will be a ~dict~,

#+begin_src jupyter-python :tangle develop_topotap.py
adjacencies = topotap.adjacency
adjacencies["local"].dataset
#+end_src

#+RESULTS:
#+begin_example
subtarget_id  circuit_id  connectome_id
1             0           0                <connsense.io.write_results.LazyMatrix object ...
2             0           0                <connsense.io.write_results.LazyMatrix object ...
3             0           0                <connsense.io.write_results.LazyMatrix object ...
4             0           0                <connsense.io.write_results.LazyMatrix object ...
5             0           0                <connsense.io.write_results.LazyMatrix object ...
                                                                 ...
235           0           0                <connsense.io.write_results.LazyMatrix object ...
236           0           0                <connsense.io.write_results.LazyMatrix object ...
237           0           0                <connsense.io.write_results.LazyMatrix object ...
238           0           0                <connsense.io.write_results.LazyMatrix object ...
239           0           0                <connsense.io.write_results.LazyMatrix object ...
Length: 239, dtype: object
#+end_example

The contents of each adjacency dataset is also lazy,

#+begin_src jupyter-python :tangle develop_topotap.py
adjacencies["local"].dataset.iloc[0].get_value()
#+end_src

#+RESULTS:
: <4570x4570 sparse matrix of type '<class 'numpy.int64'>'
: 	with 431358 stored elements in Compressed Sparse Row format>

** Extract small subtargets: An exercise in interacting with TAP HDFStore.


We have already extracted circuit data for the pipeline. To reduce test-development time we will extract a small subset of all the 240 subtargets and save to an ~extract~ directory. Structurally this will be exactly the same as the complete pipeline, just with a smaller size. The exercise will use the ~connsense-TAP-HDFStore~ and thus serve as an introduction the use of ~connsense-TAP~ to develop the analyses results further.

#+name: noteook-connsense-extract
#+begin_src jupyter-python
subtarget_gids = tap.pour_dataset("define-subtargets", "flatmap-columns/data") #gids") use
subtarget_sizes = subtarget_gids.apply(len)
subtarget_sizes
#+end_src

#+RESULTS: noteook-connsense-extract
#+begin_example
subtarget_id  circuit_id
1             0              4570
2             0              1823
3             0             17981
4             0              5597
5             0              7208
                            ...
236           0               228
237           0               345
238           0                12
239           0                 1
240           0                 0
Name: gids, Length: 240, dtype: int64
#+end_example

Let us take everything below a size of 5000
#+begin_src jupyter-python
subtargets_to_extract = (subtarget_sizes.index[np.logical_and(2000 <= subtarget_sizes.values,
                                                             subtarget_sizes.values < 5000)]
                                               .get_level_values("subtarget_id"))
print("Number 2000 <= subtarget-size < 5000", len(subtargets_to_extract))
#+end_src

#+RESULTS:
: Number 2000 <= subtarget-size < 5000 16

that we can use to define the extracted subtargets. There are three datasets associated with subtargets.

#+begin_src jupyter-python
subtarget_names = topotap.pour_dataset("define-subtargets", "flatmap-columns/name")
extract_names = subtarget_names.loc[subtargets_to_extract]
extract_gids = subtarget_gids.loc[subtargets_to_extract]
extract_info = topotap.subtargets.loc[subtargets_to_extract]
display(extract_info)
display(extract_gids)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
             subtarget  flat_i  flat_j        flat_x  flat_y
subtarget_id
1               R18;C0     -27      27  3.802528e-13  6210.0
57              R19;C5     -23      34  2.191044e+03  6555.0
58               R1;C0      -1       2  1.991858e+02   345.0
71               R0;C3       3       3  1.195115e+03     0.0
136              R0;C7       7       7  2.788602e+03     0.0
181             R8;C10      -2      22  3.983717e+03  2760.0
186             R3;C10       6      15  4.182903e+03  1035.0
205            R12;C13      -5      31  5.178832e+03  4140.0
215            R13;C13      -6      33  5.378018e+03  4485.0
216             R0;C11      11      11  4.382089e+03     0.0
217             R5;C13       6      21  5.378018e+03  1725.0
218             R7;C14       4      25  5.776389e+03  2415.0
226            R14;C14      -7      35  5.577204e+03  4830.0
228             R2;C11       8      14  4.382089e+03   690.0
230            R13;C15      -4      35  6.174761e+03  4485.0
232            R14;C15      -6      36  5.975575e+03  4830.0
#+end_example
#+begin_example
subtarget_id  circuit_id
1             0             [1636113, 996599, 3524820, 14591, 4075085, 141...
57            0             [1101211, 2018531, 1028613, 3799927, 1101208, ...
58            0             [215573, 1402361, 1768805, 3677280, 1174919, 3...
71            0             [3388343, 600993, 3961385, 2680002, 2156742, 2...
136           0             [1669658, 1215301, 1576560, 2144297, 3157284, ...
181           0             [2753113, 2959883, 1484253, 3811261, 1843970, ...
186           0             [1030593, 839524, 2494450, 202186, 815469, 318...
205           0             [1205543, 1176196, 1774839, 2015050, 1364632, ...
215           0             [1308008, 1496173, 1464634, 2194140, 1034037, ...
216           0             [3408364, 3145681, 3953930, 325523, 3143500, 2...
217           0             [3629373, 1993272, 92014, 3613841, 209440, 368...
218           0             [3552622, 1981658, 567749, 3058573, 1018407, 1...
226           0             [4096837, 2697489, 3249118, 110587, 4200169, 3...
228           0             [3165401, 3108200, 3212141, 3101038, 2467433, ...
230           0             [463147, 2694306, 2288539, 2335832, 4179316, 3...
232           0             [296143, 3478705, 166027, 2306898, 3394905, 49...
Name: gids, dtype: object
#+end_example
:END:

We can just write them to the workplace
#+begin_src jupyter-python
EXTRACTSPC = CONNSPACE / "extract-3"
EXTRACTSPC.mkdir(parents=False, exist_ok=True)
extract_info.to_hdf(EXTRACTSPC/"connsense.h5", key="subtargets/flatmap-columns/info")
extract_names.to_hdf(EXTRACTSPC/"connsense.h5", key="subtargets/flatmap-columns/name")
extract_gids.to_hdf(EXTRACTSPC/"connsense.h5", key="subtargets/flatmap-columns/data")

#+end_src

#+RESULTS:
: /gpfs/bbp.cscs.ch/home/sood/work/workspaces/venvs/py39/lib/python3.9/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'flatmap-columns'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though
:   check_attribute_name(name)
: /gpfs/bbp.cscs.ch/ssd/apps/bsd/2022-01-10/stage_applications/install_gcc-11.2.0-skylake/py-pandas-1.3.4-exvllw/lib/python3.9/site-packages/pandas/core/generic.py:2703: PerformanceWarning:
: your performance may suffer as PyTables will pickle object types that it cannot
: map directly to c-types [inferred_type->mixed,key->values] [items->None]
:
:   pytables.to_hdf(

#+begin_src jupyter-python
def count_mtypes(value):
    def in_subtarget(s):
        nodes = s.get_value()
        shapes = nodes.mtype.apply(lambda m: '_'.join(m.split('_')[1:]))
        mcs = shapes == value
        return mcs.sum()
    return count_mtypes
#+end_src

#+RESULTS:

** Working with analysis data
For our extraction we have computed ~simplex-counts~. Here we use ~TAP~ to load the data programmatically,
#+begin_src jupyter-python
tap_3 = devtap.HDFStore(EXT3SPC/"pipeline.yaml")
simplex_counts = tap_3.analyses["connectivity"]["simplex-counts"].load()
#+end_src

#+RESULTS:

We have to say ~.load()~ to load the actual data, and not just a ~table-of-contents~ of ~datacalls~. We can get datasets,
#+begin_src jupyter-python
simplex_counts.dataset["full"][ [0, 1, 2, 3] ]
#+end_src

#+RESULTS:
#+begin_example
dim                                         0         1          2          3
subtarget_id circuit_id control
1            0          erdos-renyi-0  4570.0  431358.0   840153.0    33636.0
                        original       4570.0  431358.0  2302299.0  1155649.0
57           0          erdos-renyi-0  3847.0  337286.0   673438.0    30354.0
                        original       3847.0  337286.0  1682733.0   764834.0
58           0          erdos-renyi-0  2848.0  188621.0   290366.0    10409.0
                        original       2848.0  188621.0   800842.0   353430.0
71           0          erdos-renyi-0  3694.0  269210.0   386776.0    11018.0
                        original       3694.0  269210.0  1197872.0   552570.0
136          0          erdos-renyi-0  2374.0  141944.0   213721.0     8159.0
                        original       2374.0  141944.0   576372.0   261690.0
181          0          erdos-renyi-0  3205.0  225633.0   349975.0    11822.0
                        original       3205.0  225633.0   993657.0   434499.0
186          0          erdos-renyi-0  2984.0  149416.0   125325.0     1758.0
                        original       2984.0  149416.0   547792.0   255172.0
205          0          erdos-renyi-0  2156.0  141003.0   280578.0    17094.0
                        original       2156.0  141003.0   707028.0   428920.0
215          0          erdos-renyi-0  4494.0  483092.0  1244045.0    76965.0
                        original       4494.0  483092.0  3240852.0  2317485.0
216          0          erdos-renyi-0  2947.0  221897.0   427678.0    20991.0
                        original       2947.0  221897.0  1086887.0   574999.0
217          0          erdos-renyi-0  2602.0  161116.0   237144.0     8527.0
                        original       2602.0  161116.0   619491.0   234433.0
218          0          erdos-renyi-0  3697.0  307983.0   578546.0    24451.0
                        original       3697.0  307983.0  1563867.0   780629.0
226          0          erdos-renyi-0  4944.0  526118.0  1203088.0    59375.0
                        original       4944.0  526118.0  3241978.0  1875925.0
228          0          erdos-renyi-0  2663.0  183403.0   326945.0    14986.0
                        original       2663.0  183403.0   922528.0   540581.0
230          0          erdos-renyi-0  3804.0  332390.0   668711.0    31131.0
                        original       3804.0  332390.0  1807222.0  1012530.0
232          0          erdos-renyi-0  4893.0  517354.0  1181543.0    58270.0
                        original       4893.0  517354.0  3150123.0  1818743.0
#+end_example

or

#+begin_src jupyter-python
simplex_counts.dataset["layer"][ [0, 1] ]
#+end_src

#+RESULTS:
#+begin_example
dim                                        0              1
layer                                      1       2      1        2
subtarget_id circuit_id control
1            0          erdos-renyi-0   49.0   484.0   50.0   4802.0
                        original        49.0   484.0   52.0  11524.0
57           0          erdos-renyi-0   29.0   573.0   19.0   7597.0
                        original        29.0   573.0   20.0  15270.0
58           0          erdos-renyi-0   16.0   347.0    9.0   2837.0
                        original        16.0   347.0    9.0   5605.0
71           0          erdos-renyi-0   25.0   398.0    9.0   3092.0
                        original        25.0   398.0   27.0   7489.0
136          0          erdos-renyi-0    7.0   217.0    1.0   1186.0
                        original         7.0   217.0    3.0   3214.0
181          0          erdos-renyi-0   29.0   474.0   19.0   4984.0
                        original        29.0   474.0   26.0  10842.0
186          0          erdos-renyi-0   86.0  1038.0  118.0  18099.0
                        original        86.0  1038.0  134.0  37112.0
216          0          erdos-renyi-0   52.0   875.0   78.0  19315.0
                        original        52.0   875.0   59.0  31534.0
217          0          erdos-renyi-0   39.0   409.0   35.0   3850.0
                        original        39.0   409.0   33.0   8028.0
218          0          erdos-renyi-0   40.0   615.0   49.0   8525.0
                        original        40.0   615.0   32.0  17561.0
226          0          erdos-renyi-0   24.0   436.0   10.0   4110.0
                        original        24.0   436.0   14.0  10808.0
228          0          erdos-renyi-0  137.0  1560.0  458.0  62994.0
                        original       137.0  1560.0  197.0  77924.0
230          0          erdos-renyi-0   53.0   973.0   62.0  21605.0
                        original        53.0   973.0   55.0  34844.0
232          0          erdos-renyi-0   85.0  1359.0  165.0  39528.0
                        original        85.0  1359.0  130.0  59438.0
#+end_example

We can also query by ~subtarget~ names,
#+begin_src jupyter-python
simplex_counts("R18;C0", "Bio_M")
#+end_src

#+RESULTS:
: dim                 0         1          2          3        4      5    6
: control
: erdos-renyi-0  4570.0  431358.0   840153.0    33636.0     27.0    NaN  NaN
: original       4570.0  431358.0  2302299.0  1155649.0  75857.0  916.0  2.0

#+begin_src jupyter-python
simplex_counts("R18;C0", "Bio_M", slicing="layer")[ [0, 1, 2, 3, 4] ]
#+end_src

#+RESULTS:
: dim               0            1             2            3           4
: layer             1      2     1        2    1        2   1       2   1      2
: control
: erdos-renyi-0  49.0  484.0  50.0   4802.0  NaN    984.0 NaN     4.0 NaN    NaN
: original       49.0  484.0  52.0  11524.0  4.0  28073.0 NaN  9309.0 NaN  454.0

#+begin_src jupyter-python
simplex_counts("R18;C0", "Bio_M", control="erdos-renyi-0", slicing="layer")[ [0, 1, 2, 3, 4] ]
#+end_src

#+RESULTS:
: dim               0            1             2            3           4
: layer             1      2     1        2    1        2   1       2   1      2
: control
: erdos-renyi-0  49.0  484.0  50.0   4802.0  NaN    984.0 NaN     4.0 NaN    NaN
: original       49.0  484.0  52.0  11524.0  4.0  28073.0 NaN  9309.0 NaN  454.0


We can also get ~inputs~ of a ~TapDataset~,
#+begin_src jupyter-python
simplex_counts.input("R18;C0", "Bio_M")
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
 2022-11-29 14:57:32,389: Generate inputs for ('analyze-connectivity', 'simplex-counts').
 2022-11-29 14:57:32,390: Pour tap
/gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-3/connsense.h5
 to get values for variables:
{'adjacency': {'dataset': ['extract-edge-populations', 'local']},
 'node_properties': {'dataset': ['extract-node-populations', 'default']}}
 2022-11-29 14:57:32,391: Pour adjacency dataset:
['extract-edge-populations', 'local']
 2022-11-29 14:57:32,546: Evaluate unpack_value lazily
 2022-11-29 14:57:32,547: Pour node_properties dataset:
['extract-node-populations', 'default']
 2022-11-29 14:57:32,549: Initialize a DataFrameStore matrix store loading / writing data at /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-3/connsense.h5 / nodes/populations/default
 2022-11-29 14:57:32,600: Evaluate unpack_value lazily
 2022-11-29 14:57:32,605: Load configured control erdos-renyi:
{'algorithm': {'method': 'ER_shuffle',
               'source': '/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py'},
 'description': 'Erdos-Renyi shuffle of edges.',
 'seeds': [0]}
 2022-11-29 14:57:32,606: Import module from path {'source': '/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py', 'method': 'ER_shuffle'}, with method None
 2022-11-29 14:57:32,607: Import module from path /gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py, with method ER_shuffle
 2022-11-29 14:57:32,614: Get input data from tap:
{'adjacency': {'dataset': ['extract-edge-populations', 'local']}, 'node_properties': {'dataset': ['extract-node-populations', 'default']}}
 2022-11-29 14:57:32,614: Pour tap
/gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-3/connsense.h5
 to get values for variables:
{'adjacency': {'dataset': ['extract-edge-populations', 'local']},
 'node_properties': {'dataset': ['extract-node-populations', 'default']}}
 2022-11-29 14:57:32,615: Pour adjacency dataset:
['extract-edge-populations', 'local']
 2022-11-29 14:57:32,637: Evaluate unpack_value lazily
 2022-11-29 14:57:32,637: Pour node_properties dataset:
['extract-node-populations', 'default']
 2022-11-29 14:57:32,639: Initialize a DataFrameStore matrix store loading / writing data at /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-3/connsense.h5 / nodes/populations/default
 2022-11-29 14:57:32,647: Evaluate unpack_value lazily
/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/topological-analysis-of-subvolumes/connsense/develop/topotap.py:199: PerformanceWarning: indexing past lexsort depth may impact performance.
#+end_example
: control
: original         <connsense.develop.parallelization.DataCall ob...
: erdos-renyi-0    <connsense.develop.parallelization.DataCall ob...
: dtype: object
:END:

or a specific control,
#+begin_src jupyter-python
q_controls = simplex_counts.input("R18;C0", controls="erdos-renyi")
q_controls.iloc[0]["adjacency"]
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
 2022-11-29 15:05:01,870: Generate inputs for ('analyze-connectivity', 'simplex-counts').
 2022-11-29 15:05:01,872: Pour tap
/gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-3/connsense.h5
 to get values for variables:
{'adjacency': {'dataset': ['extract-edge-populations', 'local']},
 'node_properties': {'dataset': ['extract-node-populations', 'default']}}
 2022-11-29 15:05:01,872: Pour adjacency dataset:
['extract-edge-populations', 'local']
 2022-11-29 15:05:02,038: Evaluate unpack_value lazily
 2022-11-29 15:05:02,039: Pour node_properties dataset:
['extract-node-populations', 'default']
 2022-11-29 15:05:02,040: Initialize a DataFrameStore matrix store loading / writing data at /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-3/connsense.h5 / nodes/populations/default
 2022-11-29 15:05:02,124: Evaluate unpack_value lazily
 2022-11-29 15:05:02,128: Load configured control erdos-renyi:
{'algorithm': {'method': 'ER_shuffle',
               'source': '/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py'},
 'description': 'Erdos-Renyi shuffle of edges.',
 'seeds': [0]}
 2022-11-29 15:05:02,129: Import module from path {'source': '/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py', 'method': 'ER_shuffle'}, with method None
 2022-11-29 15:05:02,130: Import module from path /gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py, with method ER_shuffle
 2022-11-29 15:05:02,137: Get input data from tap:
{'adjacency': {'dataset': ['extract-edge-populations', 'local']}, 'node_properties': {'dataset': ['extract-node-populations', 'default']}}
 2022-11-29 15:05:02,138: Pour tap
/gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-3/connsense.h5
 to get values for variables:
{'adjacency': {'dataset': ['extract-edge-populations', 'local']},
 'node_properties': {'dataset': ['extract-node-populations', 'default']}}
 2022-11-29 15:05:02,138: Pour adjacency dataset:
['extract-edge-populations', 'local']
 2022-11-29 15:05:02,159: Evaluate unpack_value lazily
 2022-11-29 15:05:02,160: Pour node_properties dataset:
['extract-node-populations', 'default']
 2022-11-29 15:05:02,161: Initialize a DataFrameStore matrix store loading / writing data at /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-3/connsense.h5 / nodes/populations/default
 2022-11-29 15:05:02,169: Evaluate unpack_value lazily
/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/topological-analysis-of-subvolumes/connsense/develop/topotap.py:198: PerformanceWarning: indexing past lexsort depth may impact performance.
  toc_idx = self.index(subtarget, circuit, connectome)
 2022-11-29 15:05:02,177: Load configured control erdos-renyi:
{'algorithm': {'method': 'ER_shuffle',
               'source': '/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py'},
 'description': 'Erdos-Renyi shuffle of edges.',
 'seeds': [0]}
 2022-11-29 15:05:02,177: Import module from path {'source': '/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py', 'method': 'ER_shuffle'}, with method None
 2022-11-29 15:05:02,178: Import module from path /gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py, with method ER_shuffle
 2022-11-29 15:05:02,544: Shuffle 2425022 edges following Erdos-Renyi
#+end_example
: <4570x4570 sparse matrix of type '<class 'numpy.int64'>'
: 	with 431358 stored elements in Compressed Sparse Row format>
:END:



* Running the pipeline

We have already configured the extract. Let us take a look into the configuration.

** Setup Launch Collect

Execution of a ~connsense-TAP-pipeline~ is done three stages:

#+begin_src shell
tap --configure=pipeline.yaml --parallelize=runtime.yaml --mode=develop setup analyze-connectivity simplex-counts
#+end_src

where we use the same ~dataset-references~ that we use in the ~connsense-TAP~ interface. The ~mode=develop~ is necessary at the moment as we have an older implementation in ~mode=prod~.

The result of setting up simplex-counts will be a workspace layout of the compute nodes where simplex-counts will be computed.
#+begin_src shell
>> tree run
├── description.json
├── full
│   ├── compute-node-0
│   ├── compute-node-1
│   ├── compute-node-10
│   ├── compute-node-11
│   ├── compute-node-12
│   ├── compute-node-13
│   ├── compute-node-14
│   ├── compute-node-15
│   ├── compute-node-16
│   ├── compute-node-17
│   ├── compute-node-18
│   ├── compute-node-19
│   ├── compute-node-2
│   ├── compute-node-3
│   ├── compute-node-4
│   ├── compute-node-5
│   ├── compute-node-6
│   ├── compute-node-7
│   ├── compute-node-8
│   ├── compute-node-9
│   ├── description.json
│   ├── launchscript.sh
│   ├── pipeline.yaml -> /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-2/run/pipeline.yaml
│   ├── runtime.yaml -> /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-2/run/runtime.yaml
│   ├── setup.json
│   └── subtargets.h5
├── layer
│   ├── compute-node-0
│   ├── compute-node-1
│   ├── compute-node-10
│   ├── compute-node-11
│   ├── compute-node-13
│   ├── compute-node-15
│   ├── compute-node-17
│   ├── compute-node-19
│   ├── compute-node-2
│   ├── compute-node-3
│   ├── compute-node-4
│   ├── compute-node-5
│   ├── compute-node-6
│   ├── compute-node-7
│   ├── compute-node-8
│   ├── compute-node-9
│   ├── description.json
│   ├── launchscript.sh
│   ├── pipeline.yaml -> /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-2/run/pipeline.yaml
│   ├── runtime.yaml -> /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-2/run/runtime.yaml
│   ├── setup.json
│   └── subtargets.h5
├── pipeline.yaml -> /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-2/run/pipeline.yaml
└── runtime.yaml -> /gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/extract-2/run/runtime.yaml

#+end_src

Each ~slicing~ will be computed in it's own directory. This can be useful in tracking the results during the development stages of a circuit-analyses suite.

** Launch

At the moment the launching of jobs is manual, but not more than a few lines. In the case of ~simplex-counts~ we will do

#+begin_src shell
>> source full/launchscript.sh
>> source layer/launchscript.sh
#+end_src

Running individual ~slicings~ can help debug during the development stages. The result of the launch will be that jobs will be queued on the cluster. We have implemented some error analysis of the jobs in ~connsense-TAP~, but error-handling is only partial at the moment. For example failure of parallel processes is not caught. We rely on reading the logs to find out-of-memory bugs, or other crashes, and plan on improving error-handling.

** Collect
Once we are satisfied with results of our analysis, we will to collect them into the master ~connsense-TAP-HDFStore~. .
#+begin_src shell
tap --configure=pipeline.yaml --parallelize=runtime.yaml --mode=develop collect analyze-connectivity simplex-counts
#+end_src


** TODO: Outline of the setup->launch->collect cycle
*** TODO Briefly about the two configs.
*** setup
*** launching
*** collect

** Pipeline Config

Let us start by configuring a ~connsense-TAP~. We will write a ~YAML~ config, starting with a header to help us track our progress.

#+name: config-header
#+begin_src jupyter-python
EXTSPC = CONNSPACE / "extract"
topotap = topotap_store.HDFStore(EXTSPC/"pipeline.yaml")
#+end_src

#+RESULTS: config-header

We can use ~topotap~ to see what we have configured,
#+begin_src jupyter-python
pprint(topotap.describe("extract-edge-populations"))
#+end_src

#+RESULTS:
: [{'dataset': ('extract-edge-populations', 'local'), 'description': None},
:  {'dataset': ('extract-edge-populations', 'long-range'),
:   'description': 'Add connections from two connectomes in section '
:                  'input/connectome'}]

Note that this description does not contain the information about the inputs, controls and slicing. We can add that as we converge to /common ontology/ of these concepts.

We can see if ~topotap~ already has these data.

where we have the adjacency matrices for the /local/ edge population

** Runtime Config maybe next time


* TAP config
There are two ~TAP~ config sections we need to fill,

** Paths

We need to first describe the input / output paths to ~connsense-TAP~. We need a path to the circuits we will analyze. ~TAP~ assumes that all of these circuits are the same /brain-model/.

#+name: config-paths
#+begin_src yaml
paths:
  description: >-
    The ~connsense~ pipeline needs paths to the input data to load from, and output paths to store data.
    Paths to the circuit must be provided along with paths to the HDF5 archive that will store the pipeline's
    results.
  format: relative
  circuit:
    root: "/gpfs/bbp.cscs.ch/project/proj83/circuits"
    files:
      Bio_M: "Bio_M/20200805/CircuitConfig_TC_WM"
  pipeline:
    root: "/gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2"
    input:
      store: "connsense.h5"
    output:
      store: "connsense.h5"
    steps:
      define-subtargets: "subtargets"
      extract-node-populations: "nodes/populations"
      extract-edge-populations: "edges/populations"
      analyze-connectivity: "analyses/connectivity"

#+end_src

As the config above suggests, we will have four distinct steps in our ~connsense-TAP~ run. We can add steps as we progress. Let us look at the four steps that we have configured.

** Parameters

*** Introduction
The second section concerns with the parameters that ~connsense-TAP~ will use to run computations. The starting point will be the definitions of ~circuit-subtargets~. We consider spatially defined subtargets, hexagonal prism shaped columns defined using a mapping to the circuit's ~flatmap~. To track the computations as the pipeline progresses, ~connsense-TAP~ will use an indexing scheme. We need to declare the variables to use in the index. Here we want to study a circuit's connectivity --- so the circuit's connectome will be one of the variables. We will have ~subtargets~ within the circuit connectome that we want to study as indpendent circuits.

#+name: config-parameters
#+begin_src yaml
parameters:
  create-index:
    description:
      Create tap-store indices by listing datasets for each index variable.
    variables:
      circuit:
        - "Bio_M"
      connectome:
        - "local"
      subtarget:
        dataset: ["define-subtargets", "flatmap-columns/name"]

#+end_src

We have used a  reference to a dataset that our ~connsense-TAP~ instance is expected to have when it needs that dataset to create an index for ~subtargets~. The reference can be read as ~(computation-type dataset)~. So here we refered to the dataset that is the result of ~define-subtargets~ dataset ~flatmap-columns/name~.

We have entered this /zeroth/ ~step~ because it is not really a ~computation~ that is run independently. The information is used within ~connsense-TAP~ for indexing.

Let us look at the steps that contain science,


*** Define Subtargets
**** Introduction

The /first/ step is to define the ~subtargets~. Each ~subtarget~ will have a name, and a set of ~gids~ associated with it. There is a variety of specifications that ~connsense-TAP~ understands. For our use we will specify path to an ~NRRD~ that maps ~voxel --> subtarget_id~, with information that maps ~subtarget_id --> subtarget info~. Along with paths to data ~connsense-TAP~ will need a method that /defines/ the subtargets. We point to a method within ~connsense~.

**** definitions
***** flatmap-columns:
Hexaongal prism like columns oriented along cortical layers, from white-matter to pia.
The data is loaded from an NRRD file that maps each circuit voxel to a subtarget ids
corresponding to a flatmap column.The subtarget ids should be mapped to the subtargets
they refer to in a dataframe provided as the input `info`.
****** input:
******* circuit
- "Bio_M"
****** kwargs
- path :: "/gpfs/bbp.cscs.ch/project/proj83/home/reimann/subvolumes/column_identities.nrrd"
- info :: "/gpfs/bbp.cscs.ch/project/proj83/home/reimann/subvolumes/voxel-based-hex-grid-info.h5"
****** loader
******* source:
connsense.define_subtargets.flatmap
******* method:
load_nrrd
****** output
pandas.DataFrame
**** YAML
#+name: config-define-subtargets
#+begin_src yaml
define-subtargets:
  description: >-
      Configure how subtargets are defined.
  definitions:
    flatmap-columns:
      description: >-
        Hexaongal prism like columns oriented along cortical layers, from white-matter to pia.
        The data is loaded from an NRRD file that maps each circuit voxel to a subtarget ids
        corresponding to a flatmap column.The subtarget ids should be mapped to the subtargets
        they refer to in a dataframe provided as the input `info`.
      input:
        circuit:
        - "Bio_M"
      kwargs:
        path: "/gpfs/bbp.cscs.ch/project/proj83/home/reimann/subvolumes/column_identities.nrrd"
        info: "/gpfs/bbp.cscs.ch/project/proj83/home/reimann/subvolumes/voxel-based-hex-grid-info.h5"
      loader:
        source: connsense.define_subtargets.flatmap
        method: load_nrrd

#+end_src

This step will save data under the references

1. ~["define-subtargets", "flatmap-columns/name"]~ that are names of each ~subtarget~
2. ~["define-subtargets", "flatmap-columns/info"]~ that is the ~info~ for each ~subtarget~
3. ~["define-subtargets", "flatmap-columns"]~ that are the gids contained in each ~subtarget~


*** Extract Node Properties
**** Introduction
Extract node properties by configuring ~extract-node-populations~,


**** populations
***** default
The default population will be that of the /biophysical-neurons/ in the SSCx.
***** input
We will extract properties of nodes in each of the subtargets.
****** subtarget
- dataset :: ["define-subtargets", "flatmap-columns"]
****** circuit
- "Bio_M"
***** kwargs
- properties ::
   - region
   - layer
   - x
   - y
   - z
   - depth
   - synapse_class
   - mtype
   - etype
   - morphology
***** extractor:
 - source :: connsense.extract_nodes.bluepy
 - method :: extract_node_properties
***** output
"pandas.DataFrame"

**** yaml

We will need node properties for each of the subtargets. We follow /SONATA/ to extract ~node-populations~ from the circuit.

#+name: config-extract-node-populations
#+begin_src yaml
extract-node-populations:
  description: >-
      Specify the populations to extract from a circuit.
  populations:
    default:
      description: >-
        The default population will be that of neurons in the SSCx.
        To extract the neurons we will use a `connsense` method that uses ~bluepy~.
      input:
        subtarget:
          dataset:  ["define-subtargets", "flatmap-columns"]
          circuit:
            - "Bio_M"
      kwargs:
        properties:
          - region
          - layer
          - x
          - y
          - z
          - depth
          - synapse_class
          - mtype
          - etype
          - morphology
      extractor:
        source: connsense.extract_nodes.bluepy
        method: extract_node_properties
      output: "pandas.DataFrame"
#+end_src

The configuration above can be used as a template to understand the general /syntax/ that ~connsense-TAP~ uses to interpret ~parameters~ entries. Each step is that of a ~computation-type~. A ~computation-type~ will have key associated with values that is a list of the ~quantities~ that will be computed.

For example, to extract nodes, we have listed ~populations~ whose nodes will be extracted. For the SSCx circuits we have only one population of biophysical cells that we named ~default~.

For each ~quantity~ to be computed, ~connsense-TAP~ will need to load it's input. In our case the inputs are the ~flatmap-columns~ that we have referenced as shown in the config. We may have more than one circuit to analyze, so that too goes in the ~inputs~. The workhorse will be the ~extractor~ specified above --- a method within ~connsense~ ---. The ~inputs~ are the arguments to the referenced ~Python~ method, and ~kwargs~ it's key-word arguments. We follow the convention that ~inputs~ can be loaded from other ~connsense-TAP~ steps and hence entered as /implicity/ references, while ~kwargs~ are some other parameters that the scientist will need to enter /explitcitly/. In the example of ~extract-node-populations~ we have specified extraction of cell properties. The ~output~ type of the method used is required by ~connsense-TAP~ to format the saved data.


*** Extract edges

We will extract subtarget edges as ~scipy.sparse~ adjacency matrices. This choice is driven mostly by the computational requirement of network topology algorithms that use adjacency matrices.

#+name: config-extract-edge-populations
#+begin_src yaml
extract-edge-populations:
  description: >-
    Specify the connectomes to extract from.
    Connections will be extracted for each subtarget as an adjacency matrix, with or without connection-strengths.
    A connection is between a pair of source and target nodes, and may be a multi-edge connection.
    We will also specify a set of edge-properties to extract from the circuit.
  populations:
    local:
      input:
        subtarget:
          dataset:  ["define-subtargets", "flatmap-columns"]
          circuit:
            - "Bio_M"
          connectome:
            - "local"
      extractor:
        source: connsense.extract_connectivity.bluepy
        method: extract_adj
      output: "sparse.spmatrix"
    #+end_src

There is nothing new here, other than the details of the computation. We specify that the inputs will be ~(subtarget, circuit, connectome)~ with their values or references. In ~kwargs~ we have set ~sources~ as /intrinsic/ which allows the ~extractor~ to distinguish extraction of connections among the /biophysical/ SSCx population from an extraction where the ~sources~ are extrinsic, for example the virtual thalamic cells defined in the reconstruction.


*** Analyze Connectivity
**** Introduction
We can have several ~analyzes-computation-types~, each motivated by the needs of the computations required by specific circuit phenomena. The scientist can choose their own name prefixed by ~analyze-~.  For our case, a study of the circuit's network topology we are interested in ~analyze-connectivity~,

#+name: config-analyze-connectivity
#+begin_src yaml
analyze-connectivity:
  description: >-
    Configure each analyses' parameters, as a mapping under section `analyses`.
#+end_src

We can list as many analyses as we want. Let us start with a computationally simple one,


**** Simplex counts
Number of simplices by dimension.
***** input:
****** adjacency
   - dataset :: ["extract-edge-populations", "local"]
****** node_properties
   - dataset :: ["extract-node-populations", "default"]
***** slicing:
Configure `do-full: true` to run the analyses on the full subtarget as a separate dataset than the slices. If `false`, analyses will not be run for full. If you do not want to analyze slices, then
****** do-full
false
****** intralayer:
Intralayer subgraphs.
******* slices:
- layer: [1, 2, 3, 4, 5, 6]
******* algorithm:
******** source
"/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py"
******** method
"subgraph_intralayer"
****** interlayer:
Interlayer subgraphs.
******* slices:
- source_layer :: [1, 2, 3, 4, 5, 6]
- target_layer :: [1, 2, 3, 4, 5, 6]
******* algorithm:
******** source
"/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py"
******** method
"subgraph_interlayer"
***** computation:
****** source
"/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py"
****** method
"simplex_counts"
***** output
"pandas.Series"

**** YAML
#+name: config-analyze-connectivity-simplex-counts
#+begin_src yaml
simplex-counts:
  description: >-
    Number of simplices by dimension.

  index:
    subtarget:
      dataset: ["define-subtargets", "flatmap-columns"]
    circuit:
      - "Bio_M"
    connectome:
      - "local"

  input:
    adjacency:
      dataset: ["extract-edge-populations", "local"]

  transformations:
    description: >-
      Transformations are configured by their type. Each type of transformation may contain several inidividual definitions. Transformations will be applied in sequence to each original input. A given transformation such as a randomization may produce more than one output for a single input. Subsequent transformations will be applied to each of it's output.  The result will be an input-dataset containing an additional level for each

  slicing:
    description: >-
      Configure `do-full: true` to run the analyses on the full subtarget as a separate dataset than the slices. If `false`, analyses will not be run for full. If you do not want to analyze slices, then
    do-full: false
    intralayer:
      description: >-
        Intralayer subgraphs.
      slices:
        layer: [1, 2, 3, 4, 5, 6]
      algorithm:
        source: "/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py"
        method: "subgraph_intralayer"
    interlayer:
      description: >-
        Interlayer subgraphs.
      slices:
        source_layer: [1, 2, 3, 4, 5, 6]
        target_layer: [1, 2, 3, 4, 5, 6]
      algorithm:
         source: "/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py"
         method: "subgraph_interlayer"


  computation:
    source: "/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py"
    method: "simplex_counts"

  output: "pandas.Series"
#+end_src

It is important to separate a ~computation~'s ~index~ from it's ~input~. The entries in ~input~ are the arguments of the ~computation-method~ entry, while ~index~ is an instruction to ~connsense-TAP~ to which subtargets the computation should be applied to. For ~simplex-counts~ we want to apply all the ~flatmap-columns~ in circuit /Bio_M/'s /local/ connectome. There are 240 of them, but one is empty, and another has only 1 node.

Using the index configured for a computation, ~connsense-TAP~ will load the inputs as configured for ~input~, a

#+begin_src example
~Mapping Argument --> DataReference~
#+end_src

We can reference a ~connsense-TAP-Dataset~ by combining ~[computation-type, of_quantity]~. For ~simplex-counts~ we want the input to be the adjacency matrices loaded from the dataset resulting from extraction of the local edge population:
#+begin_src yaml
  input:
    adjacency:
      dataset: ["extract-edge-populations", "local"]
#+end_src

~connsense-TAP~ will use the subset of this dataset that applies to the configured ~index~.


*** Result

We can write the configuration to a YAML,

#+begin_src yaml :tangle configs/pipeline.yaml :noweb yes
<<config-header>>

<<config-paths>>

<<config-parameters>>

  <<config-define-subtargets>>

  <<config-extract-node-populations>>

  <<config-extract-edge-populations>>

  <<config-analyze-connectivity>>
    analyses:
      <<config-analyze-connectivity-simplex-counts>>

#+end_src


* TAP environment


A CLI environment will allow the scientist to setup, run, and interpret a TAP instance of their circuit analysis.

#+begin_example

$ tap ?

>> What may I analyze for you today?

   1. anatomy
   2. physiology

#+end_example

To which the scientist can respond,

#+begin_example

-- anatomy

>> What aspect of anatomy?

   1. composition
   2. connectivity
   3. something else that I am not aware of?

#+end_example

We want to study the connectivity of flatmap columns,

#+begin_example

-- connectivity

#+end_example

 ~tap-env~ will look for any connectivity analyses in it's configuration, and not finding any definitions,

 #+begin_example
 >> I did not find any connectivity analyses. Do you want to configure one? (yes/no)
 #+end_example

 Let us say /yes/,

 #+begin_example

 -- yes

 >> What is the name of your analysis?

 -- simplex-counts

 >> Can you describe *simplex-counts*?

 -- Number of simplices in a network by dimension.

 >> Where can I find a method to compute *simplex-counts* ? It should be a path to a Python source file.

 --  path/to/source.py

 >> Which method in *path/to/source.py* should I use?

 -- simplex_counts

 >> What data-type does the method return?

 -- pandas.Series

 >> I have sufficient information to configure an analysis of circuit connectivity *simplex-count*

 #+end_example

~tap-env~ can use the information provided to define a YAML cell,

 #+name: config-analysis-connectivity-simplex-counts
 #+begin_src yaml
  simplex-counts:
  description: >-
    Number of simplices in a network by dimension, /i.e./ the number of nodes in the simplex.
  source: "/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py"
  method: "simplex_counts"
  output: "pandas.DataFrame"
#+end_src

#+begin_example
>> Which circuit subtargets do you want to compute?

-- flatmap-columns

>> I do not about *flatmap-columns* subtargets. Should we configure them? (yes/no)

-- yes
#+end_example

The scientist can now configure the computation of ~flatmap-columns~,

#+begin_example
>> What should we call these subtargets?

-- flatmap-columns

>> Can you describe *flatmap-columns*?

-- Conical columns, straight up along cortical layers, one per a hex-grid defined in the circuit's flatmap.

#+end_example
