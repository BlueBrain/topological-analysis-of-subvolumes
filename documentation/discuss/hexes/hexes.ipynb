{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a2ffb3-3a62-428a-b10a-dc896033313c",
   "metadata": {},
   "source": [
    "Let us setup an interactive `Python` session where we can run the code\n",
    "developed here.\n",
    "\n",
    "``` jupyter\n",
    "print(\"Welcome to EMACS Jupyter\")\n",
    "```\n",
    "\n",
    "We have an extensive configuration of the ususal 240 `flatmap-columns`\n",
    "that span the entire SSCx. There is an alternate version that has been\n",
    "used for several simulations. It is expected to cover the central area\n",
    "of the SSCx `flatmap`. Here we will develop a `connsense-pipeline` to\n",
    "compute the same analyses as the `flatmap-topology` pipeline. The only\n",
    "difference is the input flatmap columns, which are now (\\<2023-03-31\n",
    "Fri\\>) available as a dataframe.\n",
    "\n",
    "To test the configuration, we will need to setup a `Python` environment,\n",
    "\n",
    "# Setup\n",
    "\n",
    "To get the notebook you will have to clone,\n",
    "\n",
    "``` shell\n",
    "git clone https://bbpgitlab.epfl.ch/conn/structural/topological-analysis-of-subvolumes.git\n",
    "git checkout beta\n",
    "```\n",
    "\n",
    "In our discussion we will develop scientific concepts to measure the\n",
    "circuit, and implement Python functions to compute them. Here we setup a\n",
    "notebook template to test and explore, and the structure of a `Python`\n",
    "package for our methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "notebook-init",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from collections.abc import Mapping\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint, pformat\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "reload(matplotlib)\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sbn\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from bluepy import Synapse, Cell, Circuit\n",
    "\n",
    "GOLDEN = (1. + np.sqrt(5.))/2.\n",
    "print(\"We will plot golden aspect ratios: \", GOLDEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1969d83-bcba-4f0b-943c-6bbc508f0496",
   "metadata": {},
   "source": [
    "## Workspaces\n",
    "\n",
    "We have run `connsense-CRAP` for the SSCx dissemination variant *Bio-M*,\n",
    "extracting data that we will use to compute the factology. Here is a\n",
    "list of workspaces we will need to generate factsheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "notebook-workspaces",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOTSPACE = Path(\"/\")\n",
    "PROJSPACE = ROOTSPACE / \"gpfs/bbp.cscs.ch/project/proj83\"\n",
    "SOODSPACE = PROJSPACE / \"home/sood\"\n",
    "HEXTAP = SOODSPACE / \"topological-analysis-subvolumes/test/v2/hexes\"\n",
    "DEVSPACE  = HEXTAP / \"test\" / \"develop\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36c299-9feb-4d36-b694-d334c5eb4487",
   "metadata": {},
   "source": [
    "## `connsense` Modules\n",
    "\n",
    "While test-developing it will be good to have direct access to the\n",
    "`connsense-TAP-store` we will use. We will use a module from `connsense`\n",
    "to load the HDFstore,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "notebook-connsense-tap",
   "metadata": {},
   "outputs": [],
   "source": [
    "from connsense.develop import topotap as cnstap\n",
    "hextap = cnstap.HDFStore(HEXTAP/\"pipeline.yaml\")\n",
    "circuit = hextap.get_circuit(\"Bio_M\")\n",
    "print(\"Available analyses in topology tap: \")\n",
    "pprint(hextap.analyses)\n",
    "circuit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6269336-64fd-4f5c-8961-fa3f27c3cf36",
   "metadata": {},
   "source": [
    "# paths\n",
    "\n",
    "We need to set paths to the artefacts that the pipeline will use. We set\n",
    "paths for the circuit to analyze, and the root space for the pipeline's\n",
    "HDF5 stores, and the HDF5 group for each of the pipeline steps. The only\n",
    "change we need to make here, building on the config we alread have for\n",
    "`flatmap-columns`, is to set the `pipeline.root`,\n",
    "\n",
    "``` yaml\n",
    "paths:\n",
    "  description: >-\n",
    "    The ~connsense~ pipeline needs paths to the input data to load from, and output paths to store data.\n",
    "    Paths to the circuit must be provided along with paths to the HDF5 archive that will store the pipeline's\n",
    "    results.\n",
    "  format: relative\n",
    "  circuit:\n",
    "    root: \"/gpfs/bbp.cscs.ch/project/proj83/circuits\"\n",
    "    files:\n",
    "      Bio_M: \"Bio_M/20200805/CircuitConfig_TC_WM\"\n",
    "  pipeline:\n",
    "    root: \"/gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/hexes\"\n",
    "    input:\n",
    "      store: \"connsense.h5\"\n",
    "    output:\n",
    "      store: \"connsense.h5\"\n",
    "    steps:\n",
    "      define-subtargets: \"subtargets\"\n",
    "      extract-node-populations: \"nodes/populations\"\n",
    "      extract-edge-populations: \"edges/populations\"\n",
    "      analyze-connectivity: \"analyses/connectivity\"\n",
    "```\n",
    "\n",
    "# parameters\n",
    "\n",
    "We provide the parameters for each step.\n",
    "\n",
    "``` yaml\n",
    "parameters:\n",
    "  description: >-\n",
    "    Provide parameters that apply to each step.\n",
    "```\n",
    "\n",
    "The pipeline will `define` the `subtargets`, `extract` circuit artefacts\n",
    "for the `subtargets`, and `analyze` the results. Each of these `steps`\n",
    "need to be defined.\n",
    "\n",
    "## define-subtargets\n",
    "\n",
    "``` yaml\n",
    "define-subtargets:\n",
    "  description: >-\n",
    "    Configure the subtargets to analyze, entrying each definition as a key, value.\n",
    "  definitions:\n",
    "```\n",
    "\n",
    "We define `flatmap-columns` which are prism like columns orientated\n",
    "along cortical layers, from white-matter to pia. The data is loaded from\n",
    "an `NRRD` that maps each circuit voxel to an `id` that corresponds to\n",
    "`flatmap-column-subtarget`. We also need `info`, a `dataframe` that\n",
    "provides information about these `subtargets` indexing them by the `id`\n",
    "from the `NRRD`.\n",
    "\n",
    "### hexes\n",
    "\n",
    "``` yaml\n",
    "hexes:\n",
    "  description: >-\n",
    "    Columns like the flatmap columns, based on hexagonal tiling.\n",
    "  input:\n",
    "    circuit:\n",
    "    - \"Bio_M\"\n",
    "  kwargs:\n",
    "    path: \"/gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/hexes/hexes.csv\"\n",
    "  loader:\n",
    "    source: \"/gpfs/bbp.cscs.ch/project/proj83/home/sood/topological-analysis-subvolumes/test/v2/hexes/topology/pandas.py\"\n",
    "    method: \"read_csv\"\n",
    "```\n",
    "\n",
    "The `input` is set to a label that should appear among `config-paths`.\n",
    "The `loader` method used is expected to take a `bluepy.Circuit` instance\n",
    "as an argument, which will be passed by `connsense`.\n",
    "\n",
    "We need to implement the `read_csv` method to load the `hexmap-columns`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53416382-e642-4fcb-94d6-6b1702c1648b",
   "metadata": {
    "comments": "both",
    "tangle": "./topology/pandas.py"
   },
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    \"\"\"...\"\"\"\n",
    "    import pandas as pd\n",
    "    subtargets_annotation = pd.read_csv(path)\n",
    "    subtarget_ids = subtargets_annotation.subtarget_id\n",
    "    subtargets = (pd.Index(subtarget_ids.unique(), name=\"subtarget_id\").to_series()\n",
    "                  .apply(\"Hex{}\".format))\n",
    "    circuit_gidses = subtargets_annotation.groupby(\"subtarget_id\").gid.apply(list)\n",
    "    return (subtargets, None, circuit_gidses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd89886f-baf2-4c12-8c08-cb9045b4ae70",
   "metadata": {},
   "source": [
    "We have already setup the paths to load the `Python` code above from\n",
    "\\~connsense-.\n",
    "\n",
    "## create-index\n",
    "\n",
    "Within `connsense` we use an `internal` index for\n",
    "`subtarget, circuit, connectome`. While we can infer this information\n",
    "from <span class=\"spurious-link\" target=\"paths\">*paths*</span> and <span\n",
    "class=\"spurious-link\"\n",
    "target=\"define-subtargets\">*define-subtargets*</span>, we have not yet\n",
    "(\\<2023-02-13 Mon\\>) implemented this feature.\n",
    "\n",
    "``` yaml\n",
    "create-index:\n",
    "  description:\n",
    "    Create tap-store indices by listing datasets for each index variable.\n",
    "  variables:\n",
    "    circuit:\n",
    "      - \"Bio_M\"\n",
    "    connectome:\n",
    "      - \"local\"\n",
    "      - \"intra_SSCX_midrange_wm\"\n",
    "      - \"Thalamocortical_input_VPM\"\n",
    "      - \"Thalamocortical_input_POM\"\n",
    "    subtarget:\n",
    "      dataset: [\"define-subtargets\", \"hexes/name\"]\n",
    "```\n",
    "\n",
    "## extract-node-populations\n",
    "\n",
    "We will extract populations of nodes, naming them as we would like to in\n",
    "our analyses to follow.\n",
    "\n",
    "``` yaml\n",
    "extract-node-populations:\n",
    "  description: >-\n",
    "    Specify the populations to extract from a circuit.\n",
    "  populations:\n",
    "```\n",
    "\n",
    "### default\n",
    "\n",
    "The population of *non-barrel* SSCx biophysical nodes will be the\n",
    "node-population that we analyze,\n",
    "\n",
    "``` yaml\n",
    "default:\n",
    "  description: >-\n",
    "    The default population will be that of neurons in the SSCx.\n",
    "    To extract the neurons we will use a `connsense` method that uses ~bluepy~.\n",
    "  input:\n",
    "    subtarget:\n",
    "      dataset:  [\"define-subtargets\", \"hexes\"]\n",
    "    circuit:\n",
    "      - \"Bio_M\"\n",
    "  kwargs:\n",
    "    properties:\n",
    "      - region\n",
    "      - layer\n",
    "      - x\n",
    "      - y\n",
    "      - z\n",
    "      - depth\n",
    "      - synapse_class\n",
    "      - mtype\n",
    "      - etype\n",
    "      - morphology\n",
    "  extractor:\n",
    "    source: connsense.extract_nodes.bluepy\n",
    "    method: extract_node_properties\n",
    "  output: \"pandas.DataFrame\"\n",
    "```\n",
    "\n",
    "## extract-edge-populations\n",
    "\n",
    "Just as for `node-populations` we will extract `edge-populations`.\n",
    "Notice that the paths we have set in the `tap-HDFStore` are motivated by\n",
    "equivalent terminology in SONATA.\n",
    "\n",
    "``` yaml\n",
    "extract-edge-populations:\n",
    "  description: >-\n",
    "    Specify the edge populations to extract from a circuit.\n",
    "  populations:\n",
    "```\n",
    "\n",
    "We will analyze topology of the `local` connectome that consists of the\n",
    "connections among cells based on their axo-dendritic appositions. To\n",
    "study the local connectivity of a `subtarget`, we will need it's\n",
    "adjacency matrix that we can extract to the `TAPStore`.\n",
    "\n",
    "### local\n",
    "\n",
    "The population of local connections resulting from axo-dendritic\n",
    "appositions,\n",
    "\n",
    "``` yaml\n",
    "local:\n",
    "  input:\n",
    "    subtarget:\n",
    "      dataset:  [\"define-subtargets\", \"hexes\"]\n",
    "    circuit:\n",
    "      - \"Bio_M\"\n",
    "    connectome:\n",
    "      - \"local\"\n",
    "  extractor:\n",
    "    source: micasa.connsense.develop.extract.edge_populations.extract_connectivity\n",
    "    method: extract_adj\n",
    "  output: \"sparse.spmatrix\"\n",
    "```\n",
    "\n",
    "Normally extraction of edges will be a slow step.\n",
    "\n",
    "### long-range\n",
    "\n",
    "We can extract *long-rage* connectivity *between* `flatmap-columns` by\n",
    "defining computations of pairs of `flatmap-columns`.\n",
    "\n",
    "Our initial goal of extracting `long-range` connectivity is to\n",
    "investigate the topolgical structure of simplices whose\n",
    "`source-vertex lies in a selected ~flatmap-columns`. The\n",
    "`source-subtarget` `flatmap-columns` that we will be interested in will\n",
    "be determined by their `innervation` from thalamo-cortical projections.\n",
    "\n",
    "We will extract two different `long-range` edge-populations. The\n",
    "edge-population `long-range-sources` (of the `flatmap-columns`) will\n",
    "contain a `list(adjacency-matrix)` for each `flatmap-column`. For a\n",
    "given `flatmap-column` `X`, there will be one `adjacency-matrix` for\n",
    "each of another `flatmap-column` `Y`. The `adjacency-matrix` for `X, Y`\n",
    "will contain edges that have their `targets` in `X`, and `sources` in\n",
    "`Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b0d46-224d-48b1-89a0-55d5b05438f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_range_sources(flatmap_column, source_flatmap_column=None):\n",
    "    \"\"\"Long range sources of a flatmap-column.\"\"\"\n",
    "    dataset = cnstap.TapDataset(tap, (\"extract-edge-populations\", \"long-range-sources\"))\n",
    "    matrices = dataset.loc[flatmap_column, 0, 0]\n",
    "    return matrices if not source_flatmap_column else matrices.loc[source_flatmap_column]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09483ffe-77e6-4313-876e-2e8bf1dc5be2",
   "metadata": {},
   "source": [
    "will give us a `pandas.Series(adjacency-matrix)`, one for each\n",
    "`flatmap-column` among a selection of `sources`.\n",
    "\n",
    "For `long-range-targets`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52ced4-aa56-45fb-a48f-3a3c2a960076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_range_targets(flatmap_column, target_flatmap_column=None):\n",
    "    \"\"\"Long range targets of a flatmap-column.\"\"\"\n",
    "    dataset = cnstap.TapDataset(tap, (\"extract-edge-populations\", \"long-range-targets\"))\n",
    "    matrices = dataset.loc[flatmap_column, 0, 0]\n",
    "    return matrices if not target_flatmap_column else matrices.loc[target_flatmap_column]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eb42bb-4f12-4763-965c-72a7339bb33a",
   "metadata": {},
   "source": [
    "The population `long-range-sources` will be of edges (represented as\n",
    "(CSR) directed adjacency matrices), one for each pair `(X, Y)` of\n",
    "`flatmap-columns`. The `edge-population` for a `flatmap-column` `X` will\n",
    "have it's `targets` among nodes in `X`, while the `sources` of the edges\n",
    "will be among another. The primary index in `connsense` will be the\n",
    "`flatmap-column` that is receiving the `incoming` conenctions. With\n",
    "`circuit, connectome` specified, we will have another `input`, the\n",
    "`sources` that will specify a subset of `flatmap-columns` to be\n",
    "*crossed* with each dataset in `connsense-TAP` that matches the\n",
    "specification of `subtarget, circuit, connectome` inputs.\n",
    "\n",
    "Well, finally we decided to keep things explicit, with a `pre-` and a\n",
    "\\~post- specified as input arguments to the method that will extract the\n",
    "cross adjacency,\n",
    "\n",
    "``` yaml\n",
    "long-range-cross:\n",
    "  input:\n",
    "    pre:\n",
    "      dataset: [\"define-subtargets\", \"flatmap-columns\"]\n",
    "      subset: [[100, 0]]\n",
    "    circuit:\n",
    "      - \"Bio_M\"\n",
    "    connectome:\n",
    "      - \"local\"\n",
    "    post:\n",
    "      dataset: [\"define-subtargets\", \"hexes\"]\n",
    "    join: CROSS\n",
    "  computation:\n",
    "    source: micasa.connsense.develop.extract.edge_populations.extract_connectivity\n",
    "    method: extract_cross_adj\n",
    "  output: \"sparse.spmatrix\"\n",
    "```\n",
    "\n",
    "## analyze-connectivity\n",
    "\n",
    "We will analyze several phenomena related to network topology, each\n",
    "entered in `analyses`,\n",
    "\n",
    "``` yaml\n",
    "analyze-connectivity:\n",
    "  description: >-\n",
    "    Configure each analyses' parameters, as a mapping under section `analyses`.\n",
    "  analyses:\n",
    "```\n",
    "\n",
    "### simplex-counts\n",
    "\n",
    "We count the number of *simplices* that is complete subgraphs of a given\n",
    "dimension *i.e* the number of edges in the simplex. So a node is a\n",
    "simplex of dimension 0, an edge of dimension 1 while a dimension 2 will\n",
    "be a triangle. We will compute a series of simplex counts by dimension\n",
    "for each subtarget, 5 of it's Erdos-Renyi controls, subgraphs in each\n",
    "layer and their ER controls.\n",
    "\n",
    "1.  description\n",
    "\n",
    "    ``` yaml\n",
    "    simplex-counts:\n",
    "      description: >-\n",
    "        Number of simplices by dimension.\n",
    "    ```\n",
    "\n",
    "2.  input\n",
    "\n",
    "    We will compute `simplex-counts` for each of the `flatmap-columns`,\n",
    "    using `adjacency` matrices that we extract as dataset\n",
    "    `(\"extract-edge-populations\", \"local\")`. We will also use\n",
    "    `node_properties` that we extract as `node-population` `default`.\n",
    "\n",
    "    ``` yaml\n",
    "    input:\n",
    "      node_properties:\n",
    "        dataset: [\"extract-node-populations\", \"default\"]\n",
    "      adjacency:\n",
    "        dataset: [\"extract-edge-populations\", \"local\"]\n",
    "    ```\n",
    "\n",
    "3.  controls\n",
    "\n",
    "    We will use random controls for each `subtarget`, entering them by\n",
    "    name and value. We start with Erdos-Renyi controls, 5 of them\n",
    "    specified by seed.\n",
    "\n",
    "    ``` yaml\n",
    "    controls:\n",
    "      erdos-renyi:\n",
    "        description: >-\n",
    "          Erdos-Renyi shuffle of edges.\n",
    "        seeds: [0, 1, 2, 3, 4]\n",
    "        algorithm:\n",
    "          source: \"/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/randomization.py\"\n",
    "          method: \"ER_shuffle\"\n",
    "    ```\n",
    "\n",
    "4.  slicing\n",
    "\n",
    "    We will slice each `subtarget` into `subtgraphs` consisting of each\n",
    "    of the cortical layers. Thus a single `subtarget` should give us 6\n",
    "    of these `slicings`. To compute analysis on a `slicing` we will have\n",
    "    to enter it inside the `analysis` config.\n",
    "\n",
    "    We may store computation of each slice of a single subtarget as a\n",
    "    `datacall`. This will result in each slice of each subtarget to be\n",
    "    sequenced as a `unit-computation`. In `connsense-parallelization`,\n",
    "    we then parallelize based on the sizes of all the slices. The\n",
    "    computation is seprated from that of `full-subtargets`. This does\n",
    "    not work well with `simplex-counts` as `datacall` of a single\n",
    "    `slice` requires us to first load the adjacency matrices, then\n",
    "    control them. With large adjacency matrices the computation of a\n",
    "    unit `slice-subtarget` will require the same resources as loading\n",
    "    the original full and randomizing it. Instead we will have to\n",
    "    serially compute the slices' simplex-counts for each subtarget.\n",
    "\n",
    "    We can specify this in the config as `compute_mode: EXECUTE`,\n",
    "    instead of `DATACALL` which will create individual `datacalls`, or\n",
    "    `DATASET` that should save each `slice-subtarget` to a `TapDataset`.\n",
    "\n",
    "    ``` yaml\n",
    "    slicing:\n",
    "      description: >-\n",
    "        Slice analysis input according to some rules.\n",
    "      do-full: true #to run the original full matrices as well...\n",
    "      layer:\n",
    "        description: >-\n",
    "          Intralayer subgraphs.\n",
    "        compute_mode: EXECUTE\n",
    "        slices:\n",
    "          layer: [1, 2, 3, 4, 5, 6]\n",
    "        algorithm:\n",
    "          source: \"/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py\"\n",
    "          method: \"subgraph_intralayer\"\n",
    "    ```\n",
    "\n",
    "5.  computation\n",
    "\n",
    "    Finally, we need to specify the method to use to compute\n",
    "    `simplex-counts` for each `subtarget`, and the data-type of it's\n",
    "    output.\n",
    "\n",
    "    ``` yaml\n",
    "    computation:\n",
    "      source: \"/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py\"\n",
    "      method: \"simplex_counts\"\n",
    "    output: \"pandas.Series\"\n",
    "    ```\n",
    "\n",
    "### simplex-source-count of cross connectivity\n",
    "\n",
    "A simplex `s` is *efferent* to a node `n` if each of it's vertices is\n",
    "*efferently* connected to `n`. Given a `flatmap-column~s ~X` and `Y`, we\n",
    "want to count for each node `x` of `X` the number of simplices in `y`\n",
    "that are *efferent* to `x`.\n",
    "\n",
    "1.  description\n",
    "\n",
    "    ``` yaml\n",
    "    long-range-simplex-sources:\n",
    "      description: >-\n",
    "        For each node N in flatmap-column X, count the simplices in flatmap-column Y\n",
    "        that are efferent to N\n",
    "    ```\n",
    "\n",
    "2.  input\n",
    "\n",
    "    We will compute `simplex-counts` for each of the `flatmap-columns`,\n",
    "    using `adjacency` matrices that we extract as dataset\n",
    "    `(\"extract-edge-populations\", \"local\")`. We will also use\n",
    "    `node_properties` that we extract as `node-population` `default`.\n",
    "\n",
    "    ``` yaml\n",
    "    input:\n",
    "      xadj:\n",
    "        dataset: [\"extract-edge-populations\", \"long-range/sources\"]\n",
    "      node_properties:\n",
    "        datajoin:\n",
    "          pre:\n",
    "            dataset: [\"extract-node-populations\", \"default\"]\n",
    "          post:\n",
    "            dataset: [\"extract-node-populations\", \"default\"]\n",
    "      adj:\n",
    "        datajoin:\n",
    "          pre:\n",
    "            dataset: [\"extract-edge-populations\", \"local\"]\n",
    "    ```\n",
    "\n",
    "3.  computation\n",
    "\n",
    "    Finally, we need to specify the method to use to compute\n",
    "    `simplex-counts` for each `subtarget`, and the data-type of it's\n",
    "    output.\n",
    "\n",
    "    ``` yaml\n",
    "    computation:\n",
    "      source: \"/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/topology.py\"\n",
    "      method: \"simplex_counts\"\n",
    "    output: \"pandas.Series\"\n",
    "    ```\n",
    "\n",
    "### model-params-dd2\n",
    "\n",
    "This analysis is used to create parameters for the distance dependent\n",
    "connection-probablity order 2 control model.\n",
    "\n",
    "``` yaml\n",
    "model-params-dd2:\n",
    "  description: >-\n",
    "    Parameters for distance dependent connectivity model of order 2.\n",
    "    Note that the `coord_names` in key `kwargs:` must agree with the configuration\n",
    "    of the control model that will use the results of this analysis.\n",
    "```\n",
    "\n",
    "1.  input\n",
    "\n",
    "    We will compute `simplex-counts` for each of the `flatmap-columns`,\n",
    "    using `adjacency` matrices that we extract as dataset\n",
    "    `(\"extract-edge-populations\", \"local\")`. We will also use\n",
    "    `node_properties` that we extract as `node-population` `default`.\n",
    "\n",
    "    ``` yaml\n",
    "    input:\n",
    "      node_properties:\n",
    "        dataset: [\"extract-node-populations\", \"default\"]\n",
    "      adjacency:\n",
    "        dataset: [\"extract-edge-populations\", \"local\"]\n",
    "    ```\n",
    "\n",
    "2.  computation\n",
    "\n",
    "    Finally, we need to specify the method to use to compute\n",
    "    `simplex-counts` for each `subtarget`, and the data-type of it's\n",
    "    output.\n",
    "\n",
    "    ``` yaml\n",
    "    computation:\n",
    "      source: \"/gpfs/bbp.cscs.ch/project/proj83/analyses/topological-analysis-subvolumes/proj83/connectome_analysis/library/modelling.py\"\n",
    "      method: \"conn_prob_2nd_order_model\"\n",
    "    output: \"pandas.DataFrame\"\n",
    "    ```\n",
    "\n",
    "3.  kwargs\n",
    "\n",
    "    The method that we will use to compute model parameters needs these\n",
    "    parameters,\n",
    "\n",
    "    ``` yaml\n",
    "    kwargs:\n",
    "      bin_size_um: 50\n",
    "      max_range_um: 1000\n",
    "      sample_size: null\n",
    "      coord_names: [\"x\", \"y\", \"z\"]\n",
    "    ```\n",
    "\n",
    "### thalamic-innervation\n",
    "\n",
    "We will compute the number of afferent-synapses on each neuron in a\n",
    "`subtarget` from the *thalamo-cortical* projections.\n",
    "\n",
    "1.  description\n",
    "\n",
    "    ``` yaml\n",
    "    thalamic-innervation:\n",
    "      description: >-\n",
    "        Number of thalamo-cortical synapses at each cell in a subtarget.\n",
    "    ```\n",
    "\n",
    "2.  vpm:\n",
    "\n",
    "    1.  input\n",
    "\n",
    "        We will compute `simplex-counts` for each of the\n",
    "        `flatmap-columns`, using `adjacency` matrices that we extract as\n",
    "        dataset `(\"extract-edge-populations\", \"local\")`. We will also\n",
    "        use `node_properties` that we extract as `node-population`\n",
    "        `default`.\n",
    "\n",
    "        ``` yaml\n",
    "        vpm:\n",
    "          description: >-\n",
    "            Thalamic innervation of a subtarget, that originates in the VPM.\n",
    "          input:\n",
    "            subtarget:\n",
    "              dataset: [\"define-subtargets\", \"flatmap-columns\"]\n",
    "            circuit:\n",
    "              - \"Bio_M\"\n",
    "            connectome:\n",
    "              - \"Thalamocortical_input_VPM\"\n",
    "        ```\n",
    "\n",
    "    2.  computation\n",
    "\n",
    "        Finally, we need to specify the method to use to compute\n",
    "        `simplex-counts` for each `subtarget`, and the data-type of it's\n",
    "        output.\n",
    "\n",
    "        ``` yaml\n",
    "        computation:\n",
    "          source: micasa.connsense.develop.analyze.composition.projections.projections\n",
    "          method: \"innervate_cells\"\n",
    "        output: \"pandas.Series\"\n",
    "        ```\n",
    "\n",
    "3.  pom:\n",
    "\n",
    "    1.  input\n",
    "\n",
    "        We will compute `simplex-counts` for each of the\n",
    "        `flatmap-columns`, using `adjacency` matrices that we extract as\n",
    "        dataset `(\"extract-edge-populations\", \"local\")`. We will also\n",
    "        use `node_properties` that we extract as `node-population`\n",
    "        `default`.\n",
    "\n",
    "        ``` yaml\n",
    "        pom:\n",
    "          description: >-\n",
    "            Thalamic innervation of a subtarget, that originates in the VPM.\n",
    "          input:\n",
    "            subtarget:\n",
    "              dataset: [\"define-subtargets\", \"flatmap-columns\"]\n",
    "            circuit:\n",
    "              - \"Bio_M\"\n",
    "            connectome:\n",
    "              - \"Thalamocortical_input_POM\"\n",
    "        ```\n",
    "\n",
    "    2.  computation\n",
    "\n",
    "        Finally, we need to specify the method to use to compute\n",
    "        `simplex-counts` for each `subtarget`, and the data-type of it's\n",
    "        output.\n",
    "\n",
    "        ``` yaml\n",
    "        computation:\n",
    "          source: micasa.connsense.develop.analyze.composition.projections.projections\n",
    "          method: \"innervate_cells\"\n",
    "        output: \"pandas.Series\"\n",
    "        ```\n",
    "\n",
    "### cross-col-k-indegree\n",
    "\n",
    "``` yaml\n",
    "description: >-\n",
    "  Compute generalized in-degree of nodes in adj_target from nodes in adj_source.\n",
    "  The k-in-degree of a node v is the number of k-simplices in adj_source with all its nodes mapping to v\n",
    "  through edges in adj_cross\n",
    "input:\n",
    "  adj_cross:\n",
    "    dataset: [\"extract-edge-populations\", \"long-range-cross\"]\n",
    "  adj_pre:\n",
    "    dataset: [\"extract-edge-populations\", \"local\"]\n",
    "    join_index:\n",
    "      subtarget_id: pre_subtarget_id\n",
    "      circuit_id: circuit_id\n",
    "      connectome_id: DROP\n",
    "```\n",
    "\n",
    "# tap environment\n",
    "\n",
    "With `connsense` we get the `tap` command line interface command that we\n",
    "can use to setup and run a pipeline. For example, we can change\n",
    "directory to the working space for `hexes` topology we are developing\n",
    "here. We place the pipeline configuration develop above, along with the\n",
    "`runtime` config there, and\n",
    "\n",
    "``` shell\n",
    "tap init\n",
    "```\n",
    "\n",
    "To formally setup a `workspace`. We can now start running the pipeline\n",
    "step by step.\n",
    "\n",
    "## define-subtargets\n",
    "\n",
    "Before running any analyses we need to define the circuit's subtargets\n",
    "that we want to apply our analyses to. We have already configured the\n",
    "`hexes` as our `subtargets` above in <span class=\"spurious-link\"\n",
    "target=\"parameters\">*parameters*</span>. We can get `connsense` to\n",
    "define them in the `tap-store` from CLI,\n",
    "\n",
    "``` shell\n",
    "tap init define-subtargets hexes\n",
    "```\n",
    "\n",
    "Once initialized, we can directly run this step. We expect definition of\n",
    "`subtargets` to a light-weight computation, and `connsense` does not\n",
    "parallelize — as the quantity to parallelize over is defined in this\n",
    "step. To run the step,\n",
    "\n",
    "``` shell\n",
    "tap run define-subtargets hexes\n",
    "```\n",
    "\n",
    "Now we will have the subtargets in `hextap`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998704c-d9f1-473f-84f0-47dd0b409392",
   "metadata": {},
   "outputs": [],
   "source": [
    "hextap.subtarget_gids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f519b-cb43-46e7-b2da-f51be77ae080",
   "metadata": {},
   "source": [
    "We have also *named* the subtargets,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b160926b-bc7e-4b7d-8ce1-b69ff7621fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hextap.subtargets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb61d22-997f-4135-8a56-a1de33d416e6",
   "metadata": {},
   "source": [
    "## extract-node-populations\n",
    "\n",
    "For a pipeline step that will be parallelized, we need to setup it's\n",
    "execution,\n",
    "\n",
    "``` shell\n",
    "tap setup extract-node-popuations default\n",
    "```\n",
    "\n",
    "To run we will have to launch the launchscript. We need to change to the\n",
    "directory where the computation has been setup. Assuming that the\n",
    "current working directory is our `hexes` workspace,\n",
    "\n",
    "``` shell\n",
    "pushd run/extract-node-popuations/default\n",
    "source launchscript.sh\n",
    "```\n",
    "\n",
    "We will provide a direct `tap-command` to launch the jobs from CLI. Once\n",
    "all the individual compute-nodes are done running, we can collect the\n",
    "results,\n",
    "\n",
    "``` shell\n",
    "popd\n",
    "tap collect extract-node-populations default\n",
    "```\n",
    "\n",
    "The result,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc1668-1c91-44e4-92cd-6c453360503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hextap.nodes.frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523adb1b-4180-41ec-ab64-5c79eb2c9413",
   "metadata": {},
   "source": [
    "where each entry contains a dataframe of node-properties (as configured\n",
    "in <span class=\"spurious-link\" target=\"parameters\">*parameters*</span>),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab863d3-5465-4deb-8fe0-c80d9ea8d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hextap.nodes.frame.iloc[0]()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272edac8-2401-41c1-ab8b-7c2d12e672f2",
   "metadata": {},
   "source": [
    "We will be using `setup, launch, collect` for each of the computations\n",
    "that we have configured."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
